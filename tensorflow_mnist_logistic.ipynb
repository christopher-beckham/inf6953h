{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST logistic regression in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code based on: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/2_BasicModels/logistic_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# courtesy of f0k:\n",
    "# https://gist.github.com/f0k/738fa2eedd9666b78404ed1751336f56\n",
    "def load_dataset():\n",
    "    # We first define a download function, supporting both Python 2 and 3.\n",
    "    if sys.version_info[0] == 2:\n",
    "        from urllib import urlretrieve\n",
    "    else:\n",
    "        from urllib.request import urlretrieve\n",
    "\n",
    "    def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "        print(\"Downloading %s\" % filename)\n",
    "        urlretrieve(source + filename, filename)\n",
    "\n",
    "    # We then define functions for loading MNIST images and labels.\n",
    "    # For convenience, they also download the requested files if needed.\n",
    "    import gzip\n",
    "\n",
    "    def load_mnist_images(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the inputs in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        # The inputs are vectors now, we reshape them to monochrome 2D images,\n",
    "        # following the shape convention: (examples, channels, rows, columns)\n",
    "        data = data.reshape(-1, 1, 28, 28)\n",
    "        # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "        # (Actually to range [0, 255/256], for compatibility to the version\n",
    "        # provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        if not os.path.exists(filename):\n",
    "            download(filename)\n",
    "        # Read the labels in Yann LeCun's binary format.\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        # The labels are vectors of integers now, that's exactly what we want.\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "    y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "    X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "    y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    # We just return all the arrays in order, as expected in main().\n",
    "    # (It doesn't matter how we do this as long as we can read them again.)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, _, _ = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x120c84d50>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAYAAACJm/9dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhwOeGB4eDvx/Ovkf8irfy6sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120aa6310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_train[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label_to_one_hot(y_mat, num_classes=10):\n",
    "    one_hots = np.zeros((y_mat.shape[0], num_classes))\n",
    "    for i in range(one_hots.shape[0]):\n",
    "        one_hots[i][y_mat[i]] = 1.\n",
    "    return one_hots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original input is in the form of (bs, 1, 28, 28), but since we're not using conv-nets, we want to flatten this into a 28*28 = 784 vector. So let's do that here. Let's also convert the labels to one-hot representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 28*28))\n",
    "X_val = X_val.reshape((X_val.shape[0], 28*28))\n",
    "y_train_onehot = label_to_one_hot(y_train)\n",
    "y_val_onehot = label_to_one_hot(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterator(X_mat, y_mat, bs, shuffle):\n",
    "    \"\"\"\n",
    "    Mini-batch iterator for the data\n",
    "    X_mat: X data\n",
    "    y_mat: y data\n",
    "    bs: batch size\n",
    "    shuffle: pre-shuffle the data before iterating?\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        idxs = [x for x in range(X_mat.shape[0])]\n",
    "        X_mat, y_mat = X_mat[idxs], y_mat[idxs]\n",
    "    b = 0\n",
    "    while True:\n",
    "        if b*bs >= X_mat.shape[0]:\n",
    "            break\n",
    "        yield X_mat[b*bs:(b+1)*bs], y_mat[b*bs:(b+1)*bs]\n",
    "        b += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 784))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like -- unlike Theano -- to view these variables you have to run them within a 'session'. This also seems to imply that once the session finishes the variables are lost and go back to being 'unitialised'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    print sess.run(W)\n",
    "    print sess.run(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.initialize_all_variables()` is a helper function that initialises all of these variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ f(\\mathbf{x}) = softmax( \\mathbf{x}\\mathbf{W} + \\mathbf{b} )$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = tf.nn.softmax( tf.add(tf.matmul(x,W), b) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wish to minimise the loss over all (x,y):\n",
    "\n",
    "$$ \\sum_{i=1}^{k} y_{i} \\ log \\ p(y|x)_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(preds), reduction_indices=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-98-8a1a76166dcb>:1: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "epoch = 1, train loss = 0.824304, valid loss = 0.472991\n",
      "epoch = 2, train loss = 0.466413, valid loss = 0.387426\n",
      "epoch = 3, train loss = 0.410850, valid loss = 0.354316\n",
      "epoch = 4, train loss = 0.383362, valid loss = 0.335521\n",
      "epoch = 5, train loss = 0.366076, valid loss = 0.322951\n",
      "epoch = 6, train loss = 0.353871, valid loss = 0.313740\n",
      "epoch = 7, train loss = 0.344639, valid loss = 0.306589\n",
      "epoch = 8, train loss = 0.337328, valid loss = 0.300811\n",
      "epoch = 9, train loss = 0.331345, valid loss = 0.296005\n",
      "epoch = 10, train loss = 0.326328, valid loss = 0.291920\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "num_epochs = 10\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_losses, valid_losses = [], []\n",
    "        for X_batch, y_batch in iterator(X_train, y_train_onehot, bs=32, shuffle=True):\n",
    "            _, c = sess.run([optimiser, cost], feed_dict={x: X_batch, y: y_batch})\n",
    "            train_losses.append(c)\n",
    "        for X_batch, y_batch in iterator(X_val, y_val_onehot, bs=32, shuffle=False):\n",
    "            _, c, valid_preds = sess.run([optimiser, cost, preds], feed_dict={x: X_batch, y: y_batch})\n",
    "            valid_losses.append(c)\n",
    "        print \"epoch = %i, train loss = %f, valid loss = %f\" % (epoch+1, np.mean(train_losses), np.mean(valid_losses))\n",
    "    # we now want to save the model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, 'my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless you use an interactive session, once the session is over, everything is gone. So if you are running this in a non-interactive context (i.e., a regular Python script), you want to save your model using the `tf.train.Saver()` class and reload it when you open up another session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_model.data-00000-of-00001\n",
      "my_model.index\n",
      "my_model.meta\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls my_model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"my_model\"\n",
      "all_model_checkpoint_paths: \"my_model\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model\n",
      "mean accuracy on valid set: 0.921026\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "    accuracies = []\n",
    "    for X_batch, y_batch in iterator(X_val, y_val_onehot, bs=32, shuffle=False):\n",
    "        _, c, valid_preds = sess.run([optimiser, cost, preds], feed_dict={x: X_batch, y: y_batch})\n",
    "        acc = (np.argmax(valid_preds,axis=1) == np.argmax(y_batch,axis=1)).mean()\n",
    "        accuracies.append(acc)\n",
    "    print \"mean accuracy on valid set: %f\" % np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
